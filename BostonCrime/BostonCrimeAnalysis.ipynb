{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Crime Analysis\n",
    "\n",
    "## Goals\n",
    "We're going to be working with a dataset of roughly 270,000 criminal incidents in Boston for three years (March 2012 - Mar 2015). Data is hosted by the <a href=https://data.cityofboston.gov/Public-Safety/Crime-Incident-Reports/7cdf-6fgx>City of Boston</a> and released by the Boston Police Department.\n",
    "\n",
    "Our goal is to construct a spatiotemporal model of crime rate in Boston, using a model from Professor Dawn Woodward's <a href= https://people.orie.cornell.edu/woodard/ZhouMattWood13.pdf>2015 paper modeling ambulance dispatch calls</a>. We'll construct a nonhomogenous point process model, using Gaussian mixture models to model the spatial distribution (Don't worry if this is foreign to you, we'll break everything down later).\n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    "### Data Preprocessing\n",
    "In this step, we'll show how to use command line tools to quickly preprocess your data.\n",
    "\n",
    "### Exploring Temporal Dynamics\n",
    "We'll dive deeper into the temporal dynamics of crime incidents, looking for weekly and daily patterns to determine how we should best construct our model.\n",
    "\n",
    "### Exploring Spatial Dynamics\n",
    "We'll look at a couple heat maps to check  that there are indeed time varying spatial components to Boston crime data. \n",
    "\n",
    "### Notes on Data Science\n",
    "Why not just use something out of scikit learn or TensorFlow? Can't neural networks predict everything?\n",
    "\n",
    "### Introduction to Poisson Point Processes and Gaussian Mixture Models\n",
    "Stepping back for a bit from the dataset, we'll talk generally about the type of models we're going to be working with.\n",
    "\n",
    "### Model Fitting\n",
    "We'll construct a time varying Poisson point process to model crime rate \n",
    "\n",
    "### Conclusion\n",
    "We'll use everything we've built to create a simple visualization tool for crime rate and support a function $crime(time, location)$ that outputs a single score measuring crime rate as a function of time and location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Processing\n",
    "Let's take a look at our data set to see why this is necessary. The following section should be done in a Bash shell."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "man head\n",
    "#Use the man utility for help/documentation on any command line tool.\n",
    "\n",
    "#See if you can figure out how to display the first 50 lines of the data file in your terminal window.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there's a lot of information - let's first examine the NatureCode and Incident_Type_Description fields, looking at all possible values these take on. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#We'll use the awk utility. First step: see if you can print just the second field of each line.\n",
    "\n",
    "#We can pipe the output from one command line process to the next. We'll first sort the output, grouping similar keys together. Then we'll count the resulting value for each key via the uniq tool. All together (last sort to arrange by descending value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Codes: 320\n",
      "15999 LARCRT\n",
      "15932 ARREST\n",
      "14204 IVPER \n",
      "14149 IVPER\n",
      "12302 MVA\n",
      "11395 LARCEN\n",
      "8376 HITRUN\n",
      "6432 IVMV\n",
      "6406 IVPREM\n",
      "6101 BE\n",
      "6018 VANRPT\n",
      "5688 BEMVRT\n",
      "5453 LSTPRP\n",
      "5106 INVEST\n",
      "4891 BERPT \n",
      "4468 PROP\n",
      "4275 VAND\n",
      "3945 THREAT\n",
      "3906 IVMV  \n",
      "3805 IVDRUG\n",
      "3257 AB\n",
      "3202 MISPER\n",
      "2922 TSTOP \n",
      "2915 MVAINJ\n",
      "2789 MVA   \n",
      "2708 DISTRB\n",
      "2675 MVANO \n",
      "2670 LARCIP\n",
      "2495 ABIP  \n",
      "2487 FDPROP\n",
      "2442 ILLPRK\n",
      "2298 STOLMV\n",
      "2255 ABRPT \n",
      "2017 FIGHT \n",
      "1891 EDP2  \n",
      "1856 UNCONS\n",
      "1782 MVPED1\n",
      "1665 TS\n",
      "1665 NULL\n",
      "1651 UNK   \n",
      "1584 BEIP  \n",
      "1565 HARPT \n",
      "1429 REQP  \n",
      "1403 SSTOP \n",
      "1346 ARMROB\n",
      "1327 INJOFF\n",
      "1296 EDP\n",
      "1291 MISC  \n",
      "1192 CD11  \n",
      "1162 SHOTS \n",
      "1162 FIGHT\n",
      "1128 PKNIFE\n",
      "1110 VIORDR\n",
      "1101 PERGUN\n",
      "1052 REQP\n",
      "1024 ROBIP \n",
      " 979 CD35  \n",
      " 944 CARST \n",
      " 930 MVBLDR\n",
      " 894 FIREB \n",
      " 890 SS\n",
      " 884 ALARM\n",
      " 863 SHPLFT\n",
      " 862 ROBBER\n",
      " 860 LANTEN\n",
      " 843 VANIP \n",
      " 762 NIDV\n",
      " 704 MVPED2\n",
      " 686 UNKEMS\n",
      " 680 MISSIN\n",
      " 674 MISC\n",
      " 672 SHOTS\n",
      " 659 MSNCOM\n",
      " 647 ADMRPT\n",
      " 640 ROBRPT\n",
      " 628 CD11\n",
      " 613 REQEP \n",
      " 601 FDWEAP\n",
      " 598 DVIP  \n",
      " 581 NIDV  \n",
      " 580 STAB  \n",
      " 577 PDRPT \n",
      " 545 PARTY \n",
      " 541 REMOVE\n",
      " 509 CD9\n",
      " 506 BERPTA\n",
      " 501 OVRDOS\n",
      " 500 FIRE\n",
      " 498 INVCHD\n",
      " 473 TRANSP\n",
      " 455 STOLEN\n",
      " 455 ALARMC\n",
      " 452 MEET  \n",
      " 444 UNK\n",
      " 435 CRIP  \n",
      " 414 SDNDTH\n",
      " 412 DVIP\n",
      " 404 CD14  \n",
      " 397 CD19  \n",
      " 385 AOD   \n",
      " 380 CD9   \n",
      " 380 CD35\n",
      " 366 MISCRP\n",
      " 365 STAB\n",
      " 363 CARDIA\n",
      " 331 SUSPER\n",
      " 325 TRAUMA\n",
      " 322 ALARMI\n",
      " 305 SHOT  \n",
      " 304 POISON\n",
      " 291 FV    \n",
      " 283 MVARPT\n",
      " 270 REQEP\n",
      " 263 PSHOT\n",
      " 259 RECMV \n",
      " 257 ALARMR\n",
      " 242 SEXOFF\n",
      " 228 AOD\n",
      " 217 PRSCRM\n",
      " 213 SSA\n",
      " 212 CD14\n",
      " 206 CARBLK\n",
      " 205 FO\n",
      " 184 LMUSIC\n",
      " 183 CD19\n",
      " 181 HAZ   \n",
      " 180 ASLTIP\n",
      " 152 PSHOT \n",
      " 152 BUYBAK\n",
      " 147 HOMINV\n",
      " 139 ABDWRP\n",
      " 133 MVADD \n",
      " 130 CD16  \n",
      " 126 DMV   \n",
      " 125 ABDWIP\n",
      " 124 PROTES\n",
      " 121 SUSOBJ\n",
      " 121 ALARMM\n",
      " 117 TRESPS\n",
      " 108 MVACC \n",
      " 108 CHDABU\n",
      " 106 ASTEMS\n",
      " 105 VICDOG\n",
      " 105 I00040\n",
      " 100 I00027\n",
      "  98 ASSTPO\n",
      "  97 BOMBT \n",
      "  96 FDCHLD\n",
      "  94 GANG  \n",
      "  90 INJRPT\n",
      "  90 INJ\n",
      "  85 REQPE \n",
      "  80 NOISE \n",
      "  79 ALARMV\n",
      "  78 DOGBIT\n",
      "  76 EMSMVA\n",
      "  75 DWNPWR\n",
      "  72 MVINV \n",
      "  71 ALARMH\n",
      "  70 TRACK \n",
      "  70 DK    \n",
      "  69 IVLIC \n",
      "  68 BOMB\n",
      "  64 DKDIST\n",
      "  64 CURFEW\n",
      "  63 CONFPR\n",
      "  62 VIOMVL\n",
      "  62 LOCK  \n",
      "  62 CD16\n",
      "  62 CD15  \n",
      "  60 I00015\n",
      "  59 CD7   \n",
      "  58 SCHALM\n",
      "  56 BOMB  \n",
      "  54 STNING\n",
      "  54 CD15\n",
      "  52 CARJAK\n",
      "  47 KIDNAP\n",
      "  47 JUMPER\n",
      "  46 HAZMAT\n",
      "  46 CD7\n",
      "  46 ABANRE\n",
      "  45 CTYALM\n",
      "  43 REQPF \n",
      "  43 ABAN\n",
      "  42 ALARMP\n",
      "  41 PRIOR \n",
      "  41 ABANMV\n",
      "  39 BURN1 \n",
      "  38 REQFP \n",
      "  37 CD5   \n",
      "  36 DROWN \n",
      "  35 TREE  \n",
      "  35 ENVADM\n",
      "  35 DOGRPT\n",
      "  31 NOTIFY\n",
      "  31 INJAML\n",
      "  29 FDBODY\n",
      "  29 CD24  \n",
      "  29 ABANBU\n",
      "  28 TP\n",
      "  28 PRIOR\n",
      "  28 PANHAN\n",
      "  27 RECMVO\n",
      "  27 RAPRPT\n",
      "  27 OT    \n",
      "  27 CD10  \n",
      "  26 RAPE\n",
      "  26 LOCKOU\n",
      "  25 HLDPRI\n",
      "  25 ALARMB\n",
      "  24 TRFFIC\n",
      "  24 BUYBAC\n",
      "  24 ALARM \n",
      "  22 RAPEIP\n",
      "  21 RECMVI\n",
      "  21 HAZARD\n",
      "  20 VANGRP\n",
      "  20 I00039\n",
      "  20 CD5\n",
      "  19 CD23\n",
      "  19 CD19IV\n",
      "  19 CD13  \n",
      "  19 CD13\n",
      "  18 SP\n",
      "  18 CHOKE \n",
      "  18 CD1   \n",
      "  17 PRWLER\n",
      "  16 HITOBJ\n",
      "  16 FIRWKS\n",
      "  15 OT\n",
      "  15 CD303 \n",
      "  15 BRKDOG\n",
      "  15 ALERT2\n",
      "  13 RESP\n",
      "  13 CD8   \n",
      "  13 CD26  \n",
      "  13 CD24\n",
      "  12 FIRE  \n",
      "  12 CD99  \n",
      "  12 BIOT  \n",
      "  11 STREET\n",
      "  11 STALK \n",
      "  11 CD26\n",
      "  11 CD19RA\n",
      "  10 CD8\n",
      "  10 BURN\n",
      "   9 EXPLOS\n",
      "   8 MAJOR\n",
      "   8 ALARMX\n",
      "   7 TRAUMX\n",
      "   7 PROSTI\n",
      "   7 CD99\n",
      "   7 CD303\n",
      "   7 CD23  \n",
      "   6 cd11\n",
      "   6 VNDINV\n",
      "   6 DROWN\n",
      "   6 CD4   \n",
      "   6 CD19F\n",
      "   5 TRPSCH\n",
      "   5 SILCAL\n",
      "   5 EXHEM1\n",
      "   5 DRUNKS\n",
      "   5 CD4\n",
      "   4 SUSLET\n",
      "   4 REQBHA\n",
      "   4 DETAIL\n",
      "   4 CLOSE \n",
      "   4 BOMBR \n",
      "   4 ARSRPT\n",
      "   3 TEST  \n",
      "   3 LOGAN\n",
      "   3 COLB  \n",
      "   3 CODE99\n",
      "   3 CD28  \n",
      "   3 CD25  \n",
      "   3 CD20  \n",
      "   3 CD19S\n",
      "   3 CD12\n",
      "   3 BLEED\n",
      "   3 ANMRPT\n",
      "   2 cd16\n",
      "   2 VANGRI\n",
      "   2 STALK\n",
      "   2 MVAE  \n",
      "   2 CD6   \n",
      "   2 AU    \n",
      "   2 ANMBIT\n",
      "   2 ABANPH\n",
      "   1 unkems\n",
      "   1 ts\n",
      "   1 reqp\n",
      "   1 fight\n",
      "   1 cd9\n",
      "   1 aod\n",
      "   1 VIDEOC\n",
      "   1 TRAIN\n",
      "   1 TESTBP\n",
      "   1 TEST\n",
      "   1 SNOW\n",
      "   1 REQH\n",
      "   1 REFER \n",
      "   1 Prscrm\n",
      "   1 OVRCRD\n",
      "   1 NOISMV\n",
      "   1 LCKOUT\n",
      "   1 HSTG  \n",
      "   1 HAZMT2\n",
      "   1 FELONY\n",
      "   1 ESCAPP\n",
      "   1 CRASH \n",
      "   1 CD303A\n",
      "   1 CD3   \n",
      "   1 CD2   \n",
      "   1 CD18  \n",
      "   1 CD17  \n",
      "   1 C99   \n",
      "   1 BOLO\n",
      "   1 ADVISE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.call(\"awk -F ',' '{print $2}' crimedata_nh.csv | sort | uniq -c | sort -nr > keys.csv\", shell=True);\n",
    "data = open('keys.csv').readlines()\n",
    "print 'Distinct Codes: '+ str(len(data))\n",
    "print ''.join(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of these codes are pretty cryptic and there are a bunch of them. Let's see if the other field describing the crime gives better information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "#just change to the third field\n",
    "subprocess.call(\"<INSERT AWK COMMAND HERE> crimedata_nh.csv | sort | uniq -c | sort -nr > keys.csv\", shell=True);\n",
    "print ''.join(open('keys.csv').readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these are pretty obvious. There's no easy way to decipher these, so dig through to see if there's anything related.\n",
    "\n",
    "Can you figure out what Aircraft is referring to using the grep utility?\n",
    "\n",
    "Here's an example below.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grep Aircraft crimedata_nh.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what I've figured out so far:\n",
    "<ul>\n",
    "<li> <b> Aircraft </b>: oddly enough, all the exact same location, even over the span of three years. My guess is it's not an actual crime, but something that gets reported regardless. </li>\n",
    "<li> <b> InvProp, InvPer, InvVeh </b>: answered by Boston PD on their <a href=https://twitter.com/bostonpolice/status/598911393425956865>twitter</a> and guessed the rest. Investigating property, investigating person, investigating vehicle </li>\n",
    "<li> <b> Val </b>: answered by Boston PD on their <a href=https://twitter.com/bostonpolice/status/598911393425956865>twitter</a> - violation of auto law (driving w/out proper registration/license) </li>\n",
    "\n",
    "\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've figured out what all of these mean, we can start doing basic analysis.\n",
    "Let's write a file which will contain all keys, which we'll then modify to include only violent crimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crimeValues = dict();\n",
    "data = open('keys.csv').readlines()\n",
    "for line in data:\n",
    "    text = line.strip().split(' ');\n",
    "    #lower all text\n",
    "    descrip = ' '.join(text[1:]).lower(); count = int(text[0])\n",
    "    crimeValues[descrip] = count;\n",
    "# write to csv file\n",
    "keys = sorted(crimeValues.keys())\n",
    "f = open('crimeskey.csv', 'wb');\n",
    "for key in keys:\n",
    "    f.write(key +','+str(crimeValues[key])+',\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After renaming the file (to avoid accidentally overwriting our mapping), we can reload the file and assemble the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = open('<CHANGE ME TO NEW FILE NAME>').readlines();\n",
    "crimeMapping = dict();\n",
    "\n",
    "for line in data:\n",
    "    stuff = line.strip().split(',')\n",
    "    crimeMapping[stuff[0]]= int(stuff[2])\n",
    "\n",
    "#uncomment the block below to print out the dictionary\n",
    "keys = sorted(crimeMapping.keys())\n",
    "for key in keys:\n",
    "    print key + ' '*(27 - len(key)) + str(crimeMapping[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's process the raw data using our mapping, including only crimes we want to consider. This time, we'll create a final file called processed.csv to store all our actual data we want to look at, and to get rid of extraneous fields we no longer need. All we need are the descriptions, the timestamps, day of week, and location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wbfile = open('processed.csv', 'wb');\n",
    "with open('crimedata_nh.csv') as file:\n",
    "    for line in file:\n",
    "        line = line.split(',');\n",
    "        if (line[2].lower() in crimeMapping and crimeMapping[line[2].lower()] == 1):\n",
    "            wline = [line[2].lower(), line[6], line[13], line[19][2:], line [20].strip()[:-3]]\n",
    "            wbfile.write(','.join(wline)+'\\n');\n",
    "wbfile.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we've gotten preprocessing out of the way, we can finally start looking at our data for interesting patterns. I've written some general tools to help ourselves abstract data collection/parsing and the actual computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converts a timestamp to a single time object (instead of Python's datetime)\n",
    "class Time:\n",
    "    def __init__(self, stamp):\n",
    "        stuff = stamp.split(' ');\n",
    "        date = stuff[0].split('/');\n",
    "        time = stuff[1].split(':');\n",
    "        period = stuff[2];\n",
    "        toAdd = 12 if (period == 'PM') else 0;\n",
    "        hh = int(time[0]);\n",
    "        hh = 0 if (hh == 12) else int(time[0]);\n",
    "        hh+=toAdd;\n",
    "        mm = int(time[1]); sec = int(time[2]);\n",
    "        mon = int(date[0]); dd = int(date[1]); yr = int(date[2]);\n",
    "        self.yr = yr;\n",
    "        self.dd = dd;\n",
    "        self.mon = mon;\n",
    "        self.hh = hh; \n",
    "        self.mm = mm;\n",
    "        self.sec = sec;\n",
    "        self.monthMap = dict([(0, 0), (1, 31), (2, 59), (3, 90), (4, 120), (5, 151), (6, 181),\n",
    "                             (7, 212), (8, 243), (9, 273), (10, 304), (11, 334), (12, 365)])\n",
    "    \n",
    "    @property\n",
    "    def secondsSinceDay(self):\n",
    "        return (self.hh*60 + self.mm)*60+self.sec;\n",
    "    \n",
    "    @property #period where 2 hour windows\n",
    "    def dayPeriod(self):\n",
    "        return self.hh/2;\n",
    "    \n",
    "    @property\n",
    "    def daysSinceYear(self):\n",
    "        return self.monthMap[self.mon-1]+self.dd;\n",
    "\n",
    "'''\n",
    "Feed is a class that will iterate over the data. \n",
    "This will allow us to separate the logic for the details of reading a file/data and the actual computation.\n",
    "\n",
    "### CALLBACK SIGNATURES ###\n",
    "def beginCB(void):\n",
    "\n",
    "def recordCB(data):\n",
    "     data - dict with keys 'crime' (string), 'timestamp' (Time), 'dow' (int representing day of week)\n",
    "         'lat' (float), 'long' (float)'\n",
    "\n",
    "def endCB(void):\n",
    "'''\n",
    "\n",
    "class Feed:\n",
    "    # take in a file name and lists different kinds of call backs\n",
    "    # EX: Feed('processed.csv', [], [myfunc1, myfunc2], [myfunc3])\n",
    "    def __init__(self, fname = 'processed.csv', beginCBs = [], recordCBs = [], endCBs = []):\n",
    "        self._fname = fname;\n",
    "        self._beginCBs = beginCBs;\n",
    "        self._recordCBs = recordCBs;\n",
    "        self._endCBs = endCBs\n",
    "        self.daymap = dict([('Sunday', 0), ('Monday', 1), ('Tuesday', 2), ('Wednesday', 3), ('Thursday', 4), ('Friday', 5), ('Saturday', 6)])\n",
    "    \n",
    "    @property #read only file name once constructed.\n",
    "    def source(self):\n",
    "        return self._fname\n",
    "    \n",
    "    #run through files, calling appropriate callbacks\n",
    "    def run(self):\n",
    "        errCount = 0;\n",
    "        for cb in self._beginCBs:\n",
    "            cb();\n",
    "        with open(self._fname) as file:\n",
    "            for line in file:\n",
    "                line = line.split(',');\n",
    "                #Recall format is crime, timestamp, day, latitude, longitude\n",
    "                data = dict();\n",
    "                try:\n",
    "                    data['lat'] = float(line[-1]);\n",
    "                    data['long'] = float(line[-2]);\n",
    "                    data['crime'] = line[0];\n",
    "                    data['timestamp'] = Time(line[1]); data['dow'] = self.daymap[line[2]]\n",
    "                    for cb in self._recordCBs:\n",
    "                        cb(data);\n",
    "                except:\n",
    "                    errCount+=1;\n",
    "        for cb in self._endCBs:\n",
    "            cb();\n",
    "        \n",
    "        print 'Failed to read '+ str(errCount) + ' lines'\n",
    "    \n",
    "    # methods for adding callback functions to class\n",
    "    def addRecordCB(self, cb):\n",
    "        self._recordCBs.append(cb);\n",
    "    \n",
    "    def addBeginCB(self, cb):\n",
    "        self._beginCBs.append(cb);\n",
    "\n",
    "    def addEndCB(self, cb):\n",
    "        self._endCBs.append(cb);       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've written some code to structure our analysis. Let's see how to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#This class will accumulate a list of times during a week \n",
    "class TimeSeriesCollect: \n",
    "    def __init__(self, crime):\n",
    "        self.data = []\n",
    "        self.prevperiod = 0;\n",
    "        self.crime = crime\n",
    "    \n",
    "    def recordCB(self, data):\n",
    "        pass\n",
    "        #implement me! \n",
    "        #let's make our call back record the time of the crime during the week.\n",
    "        \n",
    "    ''' \n",
    "    Once we've collected the data, we get to actually do some interesting computation now.\n",
    "    Let's bin into 10 minute windows to generate a time series, then plot this result.\n",
    "    '''\n",
    "    def endCB(self):\n",
    "        ax = plt.axes([0, 1, 2, 0.5]);\n",
    "        npdata = np.array(self.data);\n",
    "        \n",
    "        # manipulate the data so we have a vector of seconds\n",
    "        \n",
    "        # use the ax.hist function of pyplot to plot a distribution\n",
    "\n",
    "        #Choose bins based on the width of windows minute windows - this is 6*24*7 bins (weekly)\n",
    "\n",
    "        plt.title(self.crime);\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model of crime data is going to use time as a variable, but at most we're going to take time of week into account (i.e. not differentiate between day of the year since we don't have that much data). But it's worth checking if we even need to go into this much level - does day of the week even impact when crimes occur significantly? Or can we get by just considering time of day. This would certainly simplify our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get a timeseries for crimes with code manslaug - how do we interface the two classes we've built?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's take a look at assault - it seems likely that weekend nights would have higher incidence rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotTSeries(crime):\n",
    "    pass\n",
    "    # implement me - shouldn't be hard, just copy the code above\n",
    "\n",
    "#I only looked at crimes with a large number of incidents\n",
    "plotTSeries('drug charges');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotTSeries('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It looks like day of week does matter from a first glance, though it can be a little hard to tell when looking at all types of crime. I found <a href=\"http://www.itl.nist.gov/div898/handbook/pmc/section4/pmc4.htm\">this resource</a> to be a good option for an introduction to time series analysis for someone with minimal statistics background.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#This class will accumulate a list of times during a week of an occurence of a crime.\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#This class will accumulate a spatial distribution of a crime of times during a week \n",
    "class SpatialDistributionCollect: \n",
    "    def __init__(self, crime = 'all'):\n",
    "        self.data = dict();\n",
    "        self.crime = crime;\n",
    "        for i in range(84):\n",
    "            self.data[i] = [];\n",
    "    \n",
    "    def recordCB(self, data):\n",
    "        pass\n",
    "        #implement me!\n",
    "        # first check if we should even be recording the crime\n",
    "            '''if (data['lat'] < -2 and data['long'] > 2):'''\n",
    "                #some data is incomplete and gets recorded with 0, 0 lat, long\n",
    "                # let's ignore this information\n",
    "\n",
    "    def plotAll(self):\n",
    "        fig = plt.figure(figsize=(10, 10));\n",
    "        ax = fig.add_subplot(1, 1, 1);\n",
    "        \n",
    "        # can you figure out how to plot all data at once?\n",
    "        \n",
    "    def endCB(self):\n",
    "        fig = plt.figure(figsize=(5, 100));\n",
    "        plt.title(self.crime);\n",
    "        for i in range(20):\n",
    "            self.data[i] = np.array(self.data[i])\n",
    "            ax = fig.add_subplot(20, 1, i+1);\n",
    "            \n",
    "            #plot 20 periods data at once\n",
    "            #implement me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some preliminary analysis that shows the strongest intraweekly variation occurs for aggravated and simple assault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSpatial(crime):\n",
    "    collect = SpatialDistributionCollect(crime);\n",
    "    f = Feed('processed.csv', [], [lambda data: collect.recordCB(data)], [lambda : collect.endCB()]);\n",
    "    f.run()\n",
    "    return collect;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "violentCrime = getSpatial('all');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would actually appear that our initial assumption that crime rate's spatial distribution varies as a function of time is false. The spatial distributions look similar, but with varying intensity (or overall crime rate) as a function of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Notes on Data Science\n",
    "Let's back up for a little bit. We've now explored our data quite a bit, finding strong evidence of a temporal component to crime rate and some (though admittedly not much) evidence of a time varying spatial distribution.\n",
    "\n",
    "Why am I walking you through a complicated model? Can't neural networks can learn everything??\n",
    "\n",
    "It's worth taking some time to comment on the recent obsession with neural networks, in particular their application to finance.\n",
    "<ul>\n",
    "    <li> Viewing neural networks as a pseudo brain is a bad way to view them - what are they really doing? </li>\n",
    "    <li> Are they really helpful for applications to quantiative finance and HFT? </li>\n",
    "</ul>\n",
    "   \n",
    "\n",
    "Here are some tips for modeling data well:\n",
    "<ul>\n",
    "    <li> Always try and use something about the problem structure. What does this mean? </li>\n",
    "    <li> What are some important features about this dataset we can use? What are some valid assumptions? </li>\n",
    "    <li> Crime rates should vary smoothly with respect to time and space, Actual crime incidents are somewhat random, meaning the fact that a crime occurs at 11:11 pm does not necessarily mean it will occur in the future and we should model crime as stemming from an underlying process.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Models\n",
    "Here we model a distribution by taking multiple Gaussians and adding them to get a simplified representation.\n",
    "See the following link for a <a href= \"https://www.ll.mit.edu/mission/cybersec/publications/publication-files/full_papers/0802_Reynolds_Biometrics-GMM.pdf\">paper</a> with more detail.\n",
    "This is what we're using to model the spatial distribution.\n",
    "\n",
    "\n",
    "## Point Processes\n",
    "### Poisson Point Processes\n",
    "A generative model for occurrence of spatial events. \n",
    "We select a number of points according to a Poisson distribution and place each one uniformly at random.\n",
    "(Why a Poisson distribution - exponential distribution for waiting time lends itself to a Poisson distribution).\n",
    "### Inhomogeneous Point Process\n",
    "This is what we're interested in - it allows us to capture the time varying spatial distribution generating the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's first aggregate all our data and fit it to a Gaussian mixture model. We'll identify the relevant Gaussian distributions in our model. First, let's take a sample to estimate how many components we think are relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "violentCrime.plotAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "from sklearn import mixture\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# construct a Gaussian Mixture Model\n",
    "def fitGMM(data, components, mincovar):\n",
    "    # initialize number of components here\n",
    "    \n",
    "    #set up a gaussian mixture model object called gmm here\n",
    "    # should only take two lines\n",
    "\n",
    "    x = np.linspace(-71.20, -70.95)\n",
    "    y = np.linspace(42.20, 42.45)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "    Z = -gmm.score_samples(XX)[0]\n",
    "    Z = Z.reshape(X.shape)\n",
    "    \n",
    "    fig = plt.figure(figsize = (10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    CS = plt.contour(X, Y, Z, norm=LogNorm(vmin=1.0, vmax=1000.0), levels=np.logspace(0, 3, 10))\n",
    "    CB = plt.colorbar(CS, shrink=0.8, extend='both')\n",
    "    \n",
    "    means = gmm.means_\n",
    "    \n",
    "    #implement me here\n",
    "    # plot both the rawdata \n",
    "    # and scatter plot the means of the GMM as well\n",
    "\n",
    "    plt.title('Negative log-likelihood predicted by GMM')\n",
    "    plt.axis('tight')\n",
    "    plt.show()\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gmm1 = fitGMM(violentCrime.alldata, 14, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gmm2 = fitGMM(violentCrime.alldata, 14, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gmm3 = fitGMM(violentCrime.alldata, 17, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gmm4 = fitGMM(violentCrime.alldata, 21, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gmm5 = fitGMM(violentCrime.alldata, 23, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Means:'\n",
    "for i in range(len(gmm4.means_)):\n",
    "    print str(gmm4.means_[i]) + '\\t' + str(gmm4.covars_[i]) + '\\t' + str(gmm4.weights_[i]) + '\\n';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so now we've settled on an initial spatial distribution for our model, how do we incorporate time varying demand?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll construct a spatial time series to determine rates $\\lambda_i$ for Poisson distributions for each interval $ i \\in [1, 84]$. To do this, we need a way of grouping the number of crimes by period to generate an approximate distribution for each interval. Fortunately, we are given the data stream in order, which means that the callback functions below will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This class will accumulate a spatial distribution of a crime of times during a week \n",
    "class PoissonDistributionCollect: \n",
    "    def __init__(self, crime = 'all'):\n",
    "        self.data = dict();\n",
    "        self.crime = crime;\n",
    "        self.prevperiod = 0;\n",
    "        self.currentcount = 0;\n",
    "        for i in range(84):\n",
    "            self.data[i] = [];\n",
    "    \n",
    "    def recordCB(self, data):\n",
    "        # Implement me\n",
    "        # again, first check if crime is valid\n",
    "        # recall that we can compute the period within the week by looking at the hour \n",
    "        #   and the day of the week from the timestamp\n",
    "        \n",
    "        # How should prevperiod and current count be updated if the period stays the same? if it changes?\n",
    "        pass\n",
    "        \n",
    "        \n",
    "\n",
    "    def plotAll(self):\n",
    "        fig = plt.figure(figsize=(6, 6));\n",
    "        ax = fig.add_subplot(1, 1, 1);\n",
    "        plt.axis([0, 83, 0, 80])\n",
    "        for i in range(1, 84):\n",
    "            ax.scatter(np.repeat(i, len(self.data[i])), np.array(self.data[i]), alpha=0.05, color='purple');\n",
    "\n",
    "    def endCB(self):\n",
    "        self.plotAll();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRateDistributions(crime):\n",
    "    collect = PoissonDistributionCollect(crime);\n",
    "    f = Feed('processed.csv', [], [lambda data: collect.recordCB(data)], [lambda : collect.endCB()]);\n",
    "    f.run()\n",
    "    return collect;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print out the rate distributions for all crimes - or explore a few"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out we don't need to do anything complicated to determine the rates $\\lambda$. We'll prove below that the maximum likelihood estimator of a Poisson distribution is in fact simply taking the average of all samples.\n",
    "\n",
    "$$\\mathbb{P}(x_1, ..., x_n | \\lambda) = \\prod_{i = 1}^n \\frac{e^{-\\lambda}\\lambda^{x_i}}{x_i!} = \\frac{e^{-n\\lambda}\\lambda^{\\sum x_i}}{\\prod_{j=1} x_j!}$$\n",
    "\n",
    "$$ ln \\mathbb{P} = -n\\lambda + (\\ln \\lambda) \\sum_{i=1}^n x_i $$\n",
    "Can you complete the proof from here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PoissonRateFitter:\n",
    "    def __init__(self, datasrc):\n",
    "        self.collected = datasrc\n",
    "        self.rates = dict();\n",
    "        \n",
    "    def computerate(self):\n",
    "        for i in range(0, 84):\n",
    "            pass\n",
    "            #implement the max likelihood estimator (note np.average function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a call to compute the crime rates\n",
    "# call this PoissonRateFitter object crimerates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotAll(datasrc, ratesrc):\n",
    "        data = datasrc.data\n",
    "        rates = ratesrc.rates\n",
    "        fig = plt.figure(figsize=(6, 6));\n",
    "        ax = fig.add_subplot(1, 1, 1);\n",
    "        plt.axis([0, 83, 0, 40])\n",
    "        #can you figure out how to plot all distributions and rates (code is very similar to the section a few cells above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# call plotAll here with the right variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we've essentially completed our model. We have decoupled the temporal and spatial components and now have a method to predict crime rate at any point. Let's build a simple function $getCrimeRate(t, loc)$ that will return our measure of crime rate as a function of time as well as a visualization tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "import matplotlib as mpl\n",
    "import gmaps\n",
    "\n",
    "class STCrimeModel:\n",
    "    \n",
    "    def __init__(self, gmm, crimerates, rawdata):\n",
    "        self.gmm = gmm;\n",
    "        self.means = gmm.means_\n",
    "        self.covar = gmm.covars_\n",
    "        self.weights = gmm.weights_\n",
    "        self.crimerates = crimerates.rates;\n",
    "        self.rawdata = rawdata.data;\n",
    "        \n",
    "    # this function isn't very interesting, just adds ellipses\n",
    "    def plotPeriod(self, period):\n",
    "        assert( period < 84 and period >=0);\n",
    "        fig = plt.figure(figsize = (7, 7))\n",
    "        ax = fig.add_subplot(111)\n",
    "        for i in range(len(self.means)):\n",
    "            v, w = linalg.eigh(self.covar[i])\n",
    "            \n",
    "            # Plot an ellipse to show the Gaussian component\n",
    "            angle = np.arctan2(w[0][1], w[0][0])\n",
    "            angle = 180 * angle / np.pi  # convert to degrees\n",
    "            v *= 300 #scaling to make stuff visible\n",
    "            alphav = min(0.5*self.weights[i]*self.crimerates[period], 1)\n",
    "            ell = mpl.patches.Ellipse(self.means[i], v[0], v[1], 180 + angle, alpha=alphav)\n",
    "            ell.set_clip_box(ax.bbox)\n",
    "            ax.add_artist(ell)\n",
    "        plt.axis([-71.20, -70.95, 42.20, 42.45]);\n",
    "        rawdata = self.rawdata[period]\n",
    "        ax.scatter(rawdata[:,0], rawdata[:,1], alpha=0.05)\n",
    "    \n",
    "    def getCrimeRate(self, hour, day, loc):\n",
    "        #day is a string (use _daymap helper), hour is int in range [0, 23]\n",
    "        # compute the period\n",
    "        # return the rate predicted by the gmm and the crime rate\n",
    "        pass\n",
    "\n",
    "    def _daymap(self, day):\n",
    "        daymap = dict([('Sunday', 0), ('Monday', 1), ('Tuesday', 2), ('Wednesday', 3), ('Thursday', 4), ('Friday', 5), ('Saturday', 6)])\n",
    "        return daymap[day];\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalmodel = STCrimeModel(gmm4, crimerates, violentCrime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalmodel.plotPeriod(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print finalmodel.getCrimeRate(2, 'Sunday', (-71.05, 42.30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now built a model that not only has a clear intuitive meaning, but additionally supports fast queries for comparing crime rates at different locations and different times. \n",
    "\n",
    "### Here are a couple ideas for further extension:\n",
    "<ul>\n",
    " <li> Use Markov Chain Monte Carlo methods to allow time varying spatial distributions - let the Gaussian mixture components stay constant, but allow the mixture weights to vary over time. What aspect of the problem does this reflect? </li>\n",
    " <li> Improve the visualization tool by incorporating the gmaps plug in to overlay models on Google Maps</li>\n",
    " <li> Impose smoothing constraints on crime rate - we treated each interval as a distinct distribution.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested Topics/Classes for Data Science:\n",
    "Basic Programming (CS2110, CS1110) <br>\n",
    "Machine Learning (CS4786, CS4780, STSCI4740) <br>\n",
    "Stochastic Processes (MATH4740, ORIE3510) <br>\n",
    "Basic Statistics (STSCI2100, STSCI 3080) <br>\n",
    "Scientific Computing (CS4250, CS4260, STSCI3520) <br>\n",
    "Differential Equations (MATH4200, MATH4280) <br>\n",
    "Time Series Analysis (STSCI4550)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Please watch for an emailed survey about the crash course!!! </b> We'd like to keep improving our crash course in future semesters. Your feedback means a lot to us, and it helps us improve from semester to semester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
